# Copy this file to .env and fill in your API keys
# cp .env.example .env

# LLM Provider: "groq" (default), "openai", or "bedrock"
LLM_PROVIDER=groq

# --- Groq Configuration ---
GROQ_API_KEY=gsk_your_key_here
# Available models: llama-3.3-70b-versatile (smart), llama-3.1-8b-instant (fast)
GROQ_MODEL=llama-3.3-70b-versatile

# --- OpenAI Configuration ---
# Only needed if LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your_key_here
# Available models: gpt-4o (smart), gpt-4o-mini (fast/cheap)
OPENAI_MODEL=gpt-4o

# --- AWS Bedrock Configuration ---
# Only needed if LLM_PROVIDER=bedrock
# Credentials: Uses AWS credential chain (run 'aws configure' or set env vars)
AWS_REGION=us-east-1
# Available models:
#   anthropic.claude-3-sonnet-20240229-v1:0 (Claude 3 Sonnet)
#   anthropic.claude-3-haiku-20240307-v1:0 (Claude 3 Haiku - fast)
#   us.meta.llama3-3-70b-instruct-v1:0 (Llama 3.3 70B)
#   meta.llama3-8b-instruct-v1:0 (Llama 3 8B - fast)
BEDROCK_MODEL=us.meta.llama3-3-70b-instruct-v1:0
